# ğŸ› ï¸ Install required packages
!pip install -q git+https://github.com/openai/whisper.git transformers deep-translator moviepy ffmpeg-python

import os
import subprocess
import time
from moviepy.editor import VideoFileClip
from google.colab import drive, files
import whisper
from transformers import MarianMTModel, MarianTokenizer
from deep_translator import GoogleTranslator
from IPython.display import display
import ipywidgets as widgets

# ğŸ“‚ Mount Google Drive
drive.mount('/content/drive')

# ğŸ•’ Format time for SRT
def format_time(seconds):
    millisec = int((seconds - int(seconds)) * 1000)
    return f"{int(seconds // 3600):02}:{int((seconds % 3600) // 60):02}:{int(seconds % 60):02},{millisec:03}"

# ğŸ“¼ Video selection widget
video_choice = widgets.RadioButtons(
    options=['Upload your own video', 'Use sample video'],
    description='Select Video:',
    style={'description_width': 'initial'}
)
display(video_choice)

# â³ Wait for user input
while not video_choice.value:
    time.sleep(1)

if video_choice.value == 'Upload your own video':
    uploaded = files.upload()
    video_path = list(uploaed.keys())[0]
else:
    video_pathh = "Your Sample Video Path"

print(f"ğŸï¸ Using video: {video_path}")

# ğŸ§± Get base name
base, ext = os.path.splitext(video_path)

# ğŸ”Š Extract audio and check duration
print("Extracting audio and checking duration...")
video = VideoFileClip(video_path)
audio_path = base + ".wav"
video.audio.write_audiofile(audio_path, logger=None)
video_duration = video.duration
print(f"â±ï¸ Video duration: {video_duration:.2f} seconds")

# ğŸ”¤ Language selection widget
print("\nğŸŒ Select languages for translation:")
marian_langs = {
    "Hindi": "hi", "Spanish": "es", "French": "fr", "German": "de", "Tamil": "ta"
}
deep_translator_langs = {
    "Assamese": "as", "Bengali": "bn", "Gujarati": "gu", "Hindi": "hi", "Kannada": "kn",
    "Kashmiri": "ks", "Konkani": "kok", "Malayalam": "ml", "Manipuri": "mni",
    "Marathi": "mr", "Nepali": "ne", "Odia": "or", "Punjabi": "pa", "Sanskrit": "sa",
    "Sindhi": "sd", "Tamil": "ta", "Telugu": "te", "Urdu": "ur"
}
all_languages = {**marian_langs, **deep_translator_langs}
lang_selector = widgets.SelectMultiple(
    options=sorted(all_languages.keys()),
    description='Languages:',
    layout={'width': '500px'},
    style={'description_width': 'initial'}
)
button = widgets.Button(description="âœ… Confirm Languages")
output = widgets.Output()
chosen_languages = []

def on_click(b):
    global chosen_languages
    with output:
        output.clear_output()
        chosen_languages = [all_languages[lang] for lang in lang_selector.value]
        print("âœ… Selected language codes:", chosen_languages)

display(lang_selector, button, output)
button.on_click(on_click)

# â³ Wait for confirmation
print("Waiting for language selection...")
while not chosen_languages:
    time.sleep(1)

# ğŸ§  Subtitle generation + translation
def run_subtitle_pipeline():
    print("ğŸ“ Transcribing with Whisper...")
    model = whisper.load_model("base")
    result = model.transcribe(audio_path)

    def write_srt(segments, texts, filename):
        with open(filename, "w", encoding="utf-8") as f:
            for i, seg in enumerate(segments):
                f.write(f"{i+1}\n")
                f.write(f"{format_time(seg['start'])} --> {format_time(seg['end'])}\n")
                f.write(texts[i] + "\n\n")

    english_segments = result['segments']
    english_texts = [seg['text'].strip() for seg in english_segments]
    english_srt_path = base + "_english.srt"
    write_srt(english_segments, english_texts, english_srt_path)
    print(f"âœ… English subtitles saved: {english_srt_path}")

    # ğŸ“¥ Load Marian models if needed
    marian_models = {}
    for lang, code in marian_langs.items():
        if code in chosen_languages:
            model_name = f"Helsinki-NLP/opus-mt-en-{code}"
            marian_models[code] = {
                "model": MarianMTModel.from_pretrained(model_name),
                "tokenizer": MarianTokenizer.from_pretrained(model_name)
            }

    def translate_marian(texts, model, tokenizer):
        model_inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
        translated = model.generate(**model_inputs)
        return tokenizer.batch_decode(translated, skip_special_tokens=True)

    translated_srts = {}

    for code in chosen_languages:
        print(f"ğŸŒ Translating to {code}...")
        if code in deep_translator_langs.values():
            translator = GoogleTranslator(source='en', target=code)
            translations = []
            for text in english_texts:
                try:
                    translations.append(translator.translate(text))
                except Exception as e:
                    print(f"âš ï¸ Translation error: {e}")
                    translations.append(text)
        else:
            model = marian_models[code]['model']
            tokenizer = marian_models[code]['tokenizer']
            translations = translate_marian(english_texts, model, tokenizer)

        srt_path = f"{base}_{code}.srt"
        write_srt(english_segments, translations, srt_path)
        translated_srts[code] = srt_path
        print(f"ğŸ“„ {code.upper()} SRT saved: {srt_path}")

    # ğŸ¬ Embed subtitles using ffmpeg
    output_path = f"{base}_srt.mkv"
    cmd = ["ffmpeg", "-y", "-i", video_path]
    for srt in translated_srts.values():
        cmd.extend(["-sub_charenc", "UTF-8", "-i", srt])
    cmd.extend(["-map", "0:v", "-map", "0:a"])
    for i in range(len(translated_srts)):
        cmd.extend(["-map", f"{i+1}:s"])
    for idx, code in enumerate(translated_srts.keys()):
        cmd.extend(["-metadata:s:s:" + str(idx), f"language={code}"])
    cmd.extend(["-c", "copy", "-scodec", "mov_text", output_path])

    print("ğŸ“¦ Embedding subtitles...")
    subprocess.run(cmd)
    print(f"âœ… Final video created: {output_path}")

    # ğŸ“¤ Save to Google Drive (safer than files.download)
    drive_output = "/content/drive/MyDrive/Colab Notebooks/final_output.mkv"
    os.rename(output_path, drive_output)
    print(f"ğŸ“ Final output saved to Drive: {drive_output}")

    # Download the Output Video
    files.download(output_path)

    # ğŸ§¹ Optional Cleanup
    for f in [audio_path, english_srt_path] + list(translated_srts.values()):
        if os.path.exists(f):
            os.remove(f)
    print("ğŸ§¼ Cleanup complete.")

# ğŸ“ Decide based on video length
if video_duration > 300:
    print("ğŸ“¹ Long video detected. Using optimized Whisper + translation pipeline...")
    run_subtitle_pipeline()
else:
    print("ğŸï¸ Short video detected. Running standard pipeline...")
    run_subtitle_pipeline()